\documentclass[11pt]{article}
\usepackage{url}
\usepackage{graphicx,DCCN2018_en}

\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}

\usepackage[utf8]{inputenc}
\linespread{1.0}

\usepackage{amsmath}

\makeatletter
\fancyhead[RO]{\small DCCN 2018\\ {17-21 September 2018}}
\fancyhead[LO]{\small Todor Balabanov, Ivan Blagoev, Kristina Dineva \\ Self Rising Tri Layers MLP for Time Series Forecasting}

\c@page=1
       
\makeatother

\title{Self Rising Tri Layers MLP for Time Series Forecasting}

\author[1]{\small T.D. Balabanov}
\author[1]{\small I.I. Blagoev}
\author[1]{\small K.I. Dineva}

\affil[1]{\footnotesize Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, acad. Georgi Bonchev Str, block 2, office 514, 1113 Sofia, Bulgaria}

\email{todorb@iinf.bas.bg, i.blagoev@iit.bas.bg, k.dineva@iit.bas.bg}

\begin{document}

\udc{004.93}

{\let\newpage\relax\maketitle}

\vskip -1.5em

\footnotetext{This work was supported by private funding of Velbazhd Software LLC.}

\begin{abstract}
Time series forecasting is an attractive and heavily researched area. A very popular approach in this field is the usage of artificial neural networks. Some artificial neural network based solutions are oriented to deep learning as training algorithm. Instead of hidden layers extension the size of input layer of tri layers multilayer perceptron is extended. The network starts with 1-1-1 topology. The input layer rise to n, according the size of input time series. In parallel hidden layer goes to m by application of pruning algorithm. Achieved topology n-m-1 is trained with classical backpropagation of the error.
\keywords{data mining, time series forecasting, artificial neural networks}
\end{abstract}

\section{Introduction}

%\subsection{Time Series}

%\subsection{Artificial Neural Networks}

%\subsection{Deep Learning}

\section{Model Proposition}

\section{Experiments \& Results}

\section{Conclusion}

\begin{thebibliography}{99}
\end{thebibliography}

\end{document}
